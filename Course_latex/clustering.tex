\section{Clustering problems}

Given a set $X$ of points, a metric $d$ over $X$ and an integer $k \geq 1$.
We want to find a set $C \in \binom{X}{k}$, of "centers", s.t. some function is minimized.

Depending on the kind of function that we want to minimize, we have a different clustering problem.
We are now going to see some of the most important ones.

\textbf{K-Means} is defined over an $\ell_2$-loss. The function to minimize is:
\[ \sum_{x \in X} \min_{c \in C} d^2(x,c) \]

\textbf{K-Median} is defined over an $\ell_1$-loss. The function to minimize is:
\[ \sum_{x \in X} \min_{c \in C} d(x,c) \]

\textbf{K-Center} is defined over an $\ell_\infty$-loss. The function to minimize is:
\[ \max_{x \in X} \min_{c \in C} d(x,c) \]

In general, one can define the clustering with any $\ell_p$-loss.

K-Means is often defined as \href{https://en.wikipedia.org/wiki/Lloyd%27s_algorithm}{Lloyd's algorithm}, which is an error.
Lloyd's algorithm has been proposed as an heuristic for solving K-Means. It is quite simple to understand, but in general it can have a bad approximation, and a bad running time.

\subsection{K-Center}
    We are going to study K-Center, which, among the three clustering problems defined above, is the one with the simplest approximation.
    In Algorithm~\ref{alg:greedy_k_center} a greedy approximation for K-Center.

    Recall that, for a point $x$, and a set of points $S$, we have defined
    \[ d(x,S) = \min_{s \in S} d(x,s) \]

    \input{algorithms/greedy_k_center.tex}

    \begin{theorem}
        \textsc{Greedy} returns a $2$-approximation for K-Center.
    \end{theorem}

    \begin{proof}
        The algorithm defines sets $C_1, \dots, C_k$ and $x_1, \dots, x_k$, s.t. for each $i$, $C_i = \{ x_1, \dots, x_i \}$.
        It also defines the distances $\Delta_1, \dots, \Delta_{k-1}$.

        Let us define:
        \begin{equation*}
            \begin{split}
                &\Delta_k = \max_{x \in X} d(x, C_k)\\
                &x_{k+1} \in \argmax_{x \in X} d(x, C_k)\\
                &C_{k+1} = C_k \cup \{ x_{k+1} \}
            \end{split}
        \end{equation*}
        Note that we are simulating an extra iteration of the for loop.

        \begin{claim}\label{claim:kcenter_1}
            $C_k$, the set returned by \textsc{Greedy}, acts as a K-Center solution of value $\Delta_k$
        \end{claim}
        \begin{proof}
            The value of $C_k$ is
            \[ C_k = \max_{x \in X} \min_{y \in C_k} d(x,y) = \max_{x \in X} d(x, C_k) = \Delta_k \]
        \end{proof}

        \begin{claim}\label{claim:kcenter_2}
            $\Delta_1 \geq \Delta_2 \geq \cdots \geq \Delta_k$ (monotone decreasing)
        \end{claim}
        \begin{proof}
            Suppose $S \subseteq T \subseteq X$, and $x \in X$.
            Then
            \[ d(x,S) = \min_{y \in S} d(x,y) \overset{S \subseteq T}{\geq} \min_{y \in T} d(x,y) = d(x,T) \]

            For each $i = 2, \dots, k$, it holds that
            \[ \Delta_{i-1} = d(x_i, C_{i-1}) \overset{\text{greedy}}{\geq} d(x_{i+1}, C_{i-1}) \overset{C_{i-1} \subseteq C_i}{\geq} d(x_{i+1}, C_i) = \Delta_i \]
        \end{proof}

        \begin{claim}\label{claim:kcenter_3}
            $\forall i = 2, \dots, k+1$, $\forall \{ x_j, x_{j'} \} \in \binom{C_i}{2}$, $d(x_j, x_{j'}) \geq \Delta_{i-1}$.
        \end{claim}
        \begin{proof}
            By induction on $i$.

            Base case ($i=2$).
            $x_2$ is at distance $\Delta_1$ from $x_1$, and thus from $C_1 = \{x_1\}$.

            Inductive case. Suppose the claim holds for $i \leq k$; we prove it for $i+1$.
            Since the claim holds at $i$, we have $\forall \{ x_j, x_{j'} \} \in \binom{C_i}{2}$, $d(x_j, x_{j'}) \geq \Delta_{i-1}$.

            The generic pair $\{ x_j, x_{j'} \} \in \binom{C_{i+1}}{2}$ either contains two points from $C_i$, or it contains $x_{i+1}$ and one point from $C_i$.
            Since $\Delta_{i-1} \geq \Delta_i$, w.m.a. that one point is $x_{i+1}$. Wlog, $x_{j'} = x_{i+1}$.
            We have $\Delta_i = \max_{x \in X} d(x, C_i) = d(x_{i+1}, C_i) = \min_{y \in C_i} d(x_{i+1}, y)$.

            Thus, $\forall x_j \in C_i$, $d(x_{i+1}, x_j) \geq \Delta_i$.
            Then, $\forall \{ x_j, x_{j'} \} \subseteq C_{i+1}$ s.t. $x_{i+1} \in \{ x_j, x_{j'} \}$, $d( x_j, x_{j'} ) \geq \Delta_i$.
        \end{proof}

        \begin{claim}\label{claim:kcenter_4}
            If $C$ is any solution, that is, $C \in \binom{X}{k}$, then
            \[ \max_{x \in X} \min_{y \in C} d(x,y) \geq \frac{\Delta_k}{2} \]
        \end{claim}
        \begin{proof}
            Let $V = \max_{x \in X} \min_{y \in C} d(x,y)$ be the value of the solution $C$.
            Then, $\forall x \in X$, $\exists y = y_x \in C$ s.t. $d(x, y_x) \leq V$.

            Consider the set $C_{k+1} = C_k \cup \{ x_{k+1} \}$, then $\cardinality{C_{k+1}} = k+1$.
            By the PigeonHole Principle (PHP), $\exists \{ x_j, x_{j'} \} \in \binom{C_{k+1}}{2}$ s.t. $y_{x_j} = y_{x_{j'}}$.

            Let $x_j, x_{j'}$ be two points of $C_{k+1}$, $x_j \neq x_{j'}$, that have the same $y \overset{\Delta}{=} y_{x_j} = y_{x_{j'}} \in C$.

            Then, $d(x_j, y) \leq V$, and $d(x_{j'}, y) \leq V$.
            By the triangle inequality $d(x_j, x_{j'}) \leq d(x_j, y) + d(y, x_{j'}) \leq 2V$.

            By Claim~\ref{claim:kcenter_3}, any two distinct points from $C_{k+1}$ are at distance at least $\Delta_k$ from one another.
            Thurs,
            \[ \Delta_k \leq d(x_j, x_{j'}) \leq 2V \rightarrow V \geq \frac{\Delta_k}{2} \]
        \end{proof}

        Claims~\ref{claim:kcenter_1} and~\ref{claim:kcenter_4} entail that \textsc{Greedy} returns a $2$-approximation.
    \end{proof}

    \begin{theorem}
        $\forall \varepsilon > 0$, K-Center is NP-Hard to approximate to $2 - \varepsilon$.
    \end{theorem}


\subsection{Dominating set}
    Input: undirected graph $G(V,E)$, $k \geq 1$

    Question: does there exist $S \in \binom{V}{k}$ s.t. $\forall v \in V$, $v \in S$ or $\exists w \in S$ s.t. $\{ v,w \} \in E$

    That is, a dominating set is one that either touches all the vertices, or it touches all the edges.

    \begin{theorem}
        The Dominating set is NP-Hard
    \end{theorem}

    Let us define the cost of a K-Center solution $S$ as
    \[ Cen(S) = \max_{v \in V} \min_{c \in S} d(v,c) \]

    \begin{theorem}
        It is NP-Hard to approximate K-Center to $\alpha$, $\forall \alpha < 2$.
    \end{theorem}

    \begin{proof}
        Let $G(V,E),k$ be an instance of Dominating Set.

        We construct a metric $d : V \times V \rightarrow \mathbb{R}$ as follows.
        For the set of points $V$:
        \begin{itemize}
            \item $d(v,w)=1$ if $\{v,w\} \in E$
            \item $d(v,w)=2$ if $\{v,w\} \in \binom{V}{2} \setminus E$
            \item $d(v,v)=0$ if $v \in V$
        \end{itemize}

        \begin{claim}
            Suppose that $S$ is a set of points s.t. $Cen(S)=1$.
            Then $S$ is a dominating set of $G(V,E)$.
        \end{claim}
        \begin{proof}
            If $S$ is s.t. $Cen(S)=1$, then $\forall v \in V$, $\exists w \in S$ s.t. either $v=w$ or $\{v,w\} \in E$. Therefore, $S$ is a dominating set of $G(V,E)$.
        \end{proof}

        Thus, if $\exists$ dominating set $S$ of $k$ nodes, then $Cen(S)=1$.

        Suppose that, instead, $\not\exists S \in \binom{V}{k}$ s.t. $S$ is a dominating set of $G(V,E)$.
        Then, no matter which $k$ nodes I pick, there will be one node $v$ of the graph that is not covered by the $k$ nodes: $\forall S \in \binom{V}{k}$, $\exists v \in V \setminus S$ s.t. $\forall w \in S$ : $\{v,w\} \not\in E$.
        Then, $d(v,S) = 2$.

        Thus, the inapproximability has been proved.
        We only need to prove that $d$ is a metric.

        Let $\{v,w,x\} \in \binom{V}{3}$.
        The triangle inequality requires that $d(v,w) + d(w,x) \geq d(v,x)$.
        We have that
        \[ d(v,w) + d(w,x) \geq 2 \geq d(v,x) \]
    \end{proof}

    Without the triangle inequality, we could have set
    \[ d(v,w) = T \gg 2 \]
    for $\{ v,w \} \in \binom{V}{2} \setminus E$.
    The inapproximability ratio would have been $\geq T$.


\subsection{K-Median}
    Given a solution $S$ for K-Median, we define the cost of $S$ as
    \[ Med(S) = \sum_{v \in V} \min_{c \in S} d(v,c) \]

    We define the problem as follows.
    Given as input a metric $d$, $V$ and $k$.
    We want to find $S \in \binom{V}{k}$ that (approximately) minimizes $Med(S)$.

    \begin{observation}
        K-Median admits a $(2n)$-approximation, where $n = \cardinality{V}$.
    \end{observation}

    \begin{proof}
        $\forall S \in \binom{V}{k}$,
        \[ Med(S) = \sum_{v \in V} \min_{c \in S} d(v,c) \]
        \[ Cen(S) = \max_{v \in V} \min_{c \in S} d(v,c) \]

        Also,
        \begin{equation*}
            \begin{split}
                Cen(S) &\leq Med(S) = \sum_{v \in V} \min_{c \in S} d(v,c) \leq\\
                    &\leq \cardinality{V} \max_{v \in V} \min_{c \in S} d(v,c) = \cardinality{V} Cen(S)
            \end{split}
        \end{equation*}

        Suppose that $S'$ is a $2$-approximation for K-Center.
        Then,
        \[ Cen(S') \leq 2 \min_{S \in \binom{V}{k}} Cen(S) \]

        So,
        \[ Med(S') \leq n \cdot Cen(S') \leq 2n \min_{S \in \binom{V}{k}} Cen(S) \leq 2n \min_{S \in \binom{V}{k}} Med(s)  \]
    \end{proof}

    Let us now see an algorithm for approximating K-Median, presented in Algorithm~\ref{alg:local_search}.

    \input{algorithms/local_search.tex}

    Questions:
    \begin{enumerate}
        \item For how many iterations does the algorithm run?
        \item Once I get to a local minimum, how close will it be to a global minimum?
    \end{enumerate}

    Let $L = \{ l_1, \dots, l_k \}$ be the solution returned by \textsc{LocalSearch}.

    Let $Q = \{q_1, \dots, q_k\}$ be an optimal solution.

    Let $\pi : Q \rightarrow L$ be a function that maps each optimal center to one of its closest \textsc{LocalSearch} center.

    Let $D_j^* = \min_{q \in Q} d(j,q)$, $\forall j \in V$. $D_j^*$ is the cost paid by the optimal solution for point $j$.

    Let $D_j = \min_{l \in L} d(j,l)$, $\forall j \in V$. $D_j$ is the cost paid by the LS solution, for point $j$.

    Let $L_1, L_2, \dots, L_k$ be the partition of $V$ induced by the centers of $L$.
    That is, $\forall l \in L$, $j \in L_i \rightarrow d(j,l_i) \leq d(j,l)$.

    Let $Q_1, Q_2, \dots, Q_k$ be the partition of $B$ induced be the center of $Q$.
    That is, $\forall q \in Q$, $j \in Q_i \rightarrow d(j,q_i) \leq d(j,q)$.

    \begin{equation*}
        \begin{split}
            &\textsc{OPT} = \sum_{j \in V} D_j^* = \sum_{j \in V} \min_{q \in Q} d(j,q) = \sum_{i=1}^{k} \sum_{j \in Q_i} d(j,q_i)\\
            &\textsc{ALG} = \sum_{j \in V} D_j = \sum_{j \in V} \min_{l \in L} d(j,l) = \sum_{i=1}^{k} \sum_{j \in L_i} d(j,l_i)
        \end{split}
    \end{equation*}

    Our goal is to bound $\frac{\textsc{ALG}}{\textsc{OPT}}$.

    We first consider the special case where $\pi$ is a bijection.
    If $\pi$ is a bijection, we can assume, wlog, that $\pi(q_i) = l_i$, $\forall i \in \{ 1, \dots, k \}$.